{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd6aadf-a1f6-4baf-aa15-c56e9a5f8d60",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#class_weights\n",
    "\n",
    "https://medium.com/@zergtant/use-weighted-loss-function-to-solve-imbalanced-data-classification-problems-749237f38b75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "010baf86-e1b6-4965-8601-203724753d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "sys.path.append(\"../tf_ifenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af4ff73-06df-472c-b2a7-e9368ac93f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf9d1046-3839-46e1-bc7a-5ffa784f9f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from model import IFENetClassifier\n",
    "#from config import DataConfig, ModelConfig\n",
    "#from utility import dataframe_to_dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# from config import DataConfig, ModelConfig\n",
    "from tensorflow.keras.saving import register_keras_serializable, serialize_keras_object, deserialize_keras_object\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from typing import List, Optional\n",
    "\n",
    "def dataframe_to_dataset(dataframe, target_columns, batch_size=128, shuffle=True):\n",
    "    \"\"\"\n",
    "    Converts a Pandas DataFrame to a TensorFlow Dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): The input dataframe.\n",
    "        target_columns (list): List of column names to use as targets.\n",
    "        batch_size (int): Batch size for the dataset.\n",
    "        shuffle (bool): Whether to shuffle the dataset.\n",
    "    \n",
    "    Returns:\n",
    "        tf.data.Dataset: A TensorFlow Dataset object.\n",
    "    \"\"\"\n",
    "    if not isinstance(dataframe, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a Pandas DataFrame.\")\n",
    "    if not isinstance(target_columns, list):\n",
    "        raise ValueError(\"Target columns must be provided as a list.\")\n",
    "    \n",
    "    try:\n",
    "        df_copy = dataframe.copy()\n",
    "        \n",
    "        for target in target_columns:\n",
    "            if target not in df_copy.columns:\n",
    "                raise KeyError(f\"Target column '{target}' not found in the DataFrame.\")\n",
    "            if df_copy[target].dtypes == 'object':\n",
    "                df_copy[target] = df_copy[target].astype('category').cat.codes\n",
    "        \n",
    "        # targets = df_copy.loc[:,target_columns]\n",
    "        targets = df_copy[target_columns].copy()\n",
    "        df_copy.drop(columns=target_columns, inplace=True)\n",
    "        \n",
    "        df_copy = {key: value.to_numpy()[:,tf.newaxis] for key, value in df_copy.items()}\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((dict(df_copy), targets))\n",
    "        \n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(batch_size*2).batch(batch_size).prefetch(batch_size)\n",
    "        else:\n",
    "            dataset = dataset.batch(batch_size).prefetch(batch_size)\n",
    "        return dataset\n",
    "        \n",
    "    except KeyError:\n",
    "        raise KeyError(f\"Target column '{e.args[0]}' is missing from the DataFrame.\")\n",
    "\n",
    "class DataConfig():\n",
    "    \"\"\"\n",
    "    Configuration for dataset preprocessing.\n",
    "    \n",
    "    Attributes:\n",
    "        categorical_column_names: List of categorical column names.\n",
    "        numerical_column_names: List of numerical column names.\n",
    "        category_output_mode: How categorical features are encoded ('one_hot', 'multi_hot', etc.).\n",
    "        is_normalization: Whether to normalize numerical features.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        categorical_column_names: List[str], \n",
    "        numerical_column_names: List[str],  \n",
    "        category_output_mode: str = 'one_hot', \n",
    "        is_normalization: bool = False\n",
    "    ):\n",
    "        if not isinstance(categorical_column_names, list) or not all(isinstance(col, str) for col in categorical_column_names):\n",
    "            raise TypeError(\"categorical_column_names must be a list of strings.\")\n",
    "        \n",
    "        if not isinstance(numerical_column_names, list) or not all(isinstance(col, str) for col in numerical_column_names):\n",
    "            raise TypeError(\"numerical_column_names must be a list of strings.\")\n",
    "        \n",
    "        if category_output_mode not in {'one_hot', 'multi_hot'}:\n",
    "            raise ValueError(\"category_output_mode must be 'one_hot' or 'multi_hot'\")\n",
    "\n",
    "        if not isinstance(is_normalization, bool):\n",
    "            raise TypeError(\"is_normalization must be a boolean value.\")\n",
    "        \n",
    "        self.categorical_column_names = categorical_column_names\n",
    "        self.numerical_column_names = numerical_column_names\n",
    "        self.category_output_mode = category_output_mode\n",
    "        self.is_normalization = is_normalization\n",
    "        \n",
    "    def get_config(self):\n",
    "        # Return the configuration parameters as a dictionary\n",
    "        config = {\n",
    "            \"categorical_column_names\": self.categorical_column_names,\n",
    "            \"numerical_column_names\": self.numerical_column_names,\n",
    "            \"category_output_mode\": self.category_output_mode,\n",
    "            \"is_normalization\": self.is_normalization\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(\n",
    "            config[\"categorical_column_names\"],\n",
    "            config[\"numerical_column_names\"],\n",
    "            config[\"category_output_mode\"],\n",
    "            config[\"is_normalization\"]\n",
    "        )\n",
    "            \n",
    "class ModelConfig():\n",
    "    \"\"\"\n",
    "    Configuration for model architecture.\n",
    "    \n",
    "    Attributes:\n",
    "        num_att: Number of attention heads.\n",
    "        r: An amplification coefficient. Must be 1 or greater.\n",
    "        clf_num_layers: Number of layers in the predictive layers. Must be 1 or greater.\n",
    "        clf_hidden_units: Hidden units in the classification head. \n",
    "                          Must align with clf_num_layers.\n",
    "        reduction_layer: Method for dimensionality reduction ('flatten', 'average').\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_att: int = 16, \n",
    "        r: float = 3.0, \n",
    "        clf_num_layers: int = 1, \n",
    "        clf_hidden_units: List[int] = [64], \n",
    "        reduction_layer: str = 'flatten'\n",
    "    ):\n",
    "        if not isinstance(num_att, int) or num_att <= 0:\n",
    "            raise ValueError(\"num_att must be a positive integer.\")\n",
    "\n",
    "        if not isinstance(r, (float, int)) or r < 1:\n",
    "            raise ValueError(\"r must be a float or integer greater than or equal to 1.\")\n",
    "\n",
    "        if not isinstance(clf_num_layers, int) or clf_num_layers < 1:\n",
    "            raise ValueError(\"clf_num_layers must be an integer greater than or equal to 1.\")\n",
    "            \n",
    "        if reduction_layer not in {'flatten', 'average'}:\n",
    "            raise ValueError(\"reduction_layer must be 'flatten' or 'average'\")\n",
    "\n",
    "        if not isinstance(clf_hidden_units, list) or not all(isinstance(unit, int) and unit > 0 for unit in clf_hidden_units):\n",
    "            raise TypeError(\"clf_hidden_units must be a list of positive integers.\")\n",
    "            \n",
    "        if len(clf_hidden_units) != clf_num_layers:\n",
    "            raise ValueError(\n",
    "                f\"clf_hidden_units must have exactly {clf_num_layers} elements. \"\n",
    "                f\"Got {len(clf_hidden_units)} elements instead.\"\n",
    "            )\n",
    "            \n",
    "        self.num_att = num_att\n",
    "        self.r = r\n",
    "        #self.ife_num_layers = 1\n",
    "        self.clf_num_layers = clf_num_layers\n",
    "        self.clf_hidden_units = clf_hidden_units\n",
    "        self.reduction_layer = reduction_layer\n",
    "\n",
    "    def get_config(self):\n",
    "        # Return the configuration parameters as a dictionary\n",
    "        config = {\n",
    "            \"num_att\": self.num_att,\n",
    "            \"r\": self.r,\n",
    "            #\"ife_num_layers\": self.ife_num_layers,\n",
    "            \"clf_num_layers\": self.clf_num_layers,\n",
    "            \"clf_hidden_units\": self.clf_hidden_units,\n",
    "            \"reduction_layer\": self.reduction_layer\n",
    "        }\n",
    "        return config\n",
    "        \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(\n",
    "            config[\"num_att\"],\n",
    "            config[\"r\"],\n",
    "            config[\"clf_num_layers\"],\n",
    "            config[\"clf_hidden_units\"],\n",
    "            config[\"reduction_layer\"]\n",
    "        )\n",
    "\n",
    "@register_keras_serializable(name=\"_Attention\")\n",
    "class _Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, attn_norm_fn, num_att, r=2, initializer=\"glorot_uniform\", name=None, **kwargs):\n",
    "        super(_Attention, self).__init__()\n",
    "        self.units = units # number of classes/responses\n",
    "        self.attn_norm_fn = attn_norm_fn\n",
    "        self.num_att = num_att\n",
    "        self.r = r\n",
    "        self.initializer = initializer\n",
    "        if self.attn_norm_fn == 'sigmoid':\n",
    "            self.norm_function = tf.keras.layers.Activation(activation='sigmoid')\n",
    "        else:\n",
    "            self.norm_function = tf.keras.layers.Softmax()\n",
    "\n",
    "    def build(self, input_shape): # input_shape = (batch, n_features)\n",
    "        self.kernel = self.add_weight(shape=(self.num_att, input_shape[-1], self.units),\n",
    "                                      initializer=self.initializer,\n",
    "                                      trainable=True,\n",
    "                                      name='kernel') # shape = (num_att, n_features, n_outputs)\n",
    "\n",
    "    def call(self, inputs): # input_shape = (batch, n_features)\n",
    "        z = tf.matmul(inputs, self.kernel) # (batch, n_features) dot (num_att, n_features, n_outputs) = (num_att, batch, n_outputs)\n",
    "        # z = tf.nn.softmax(z, axis=-1) # (num_att, batch, n_outputs)\n",
    "        z = self.norm_function(z) # (num_att, batch, n_outputs)\n",
    "        \n",
    "        w = tf.math.exp(self.kernel * self.r) # amplify weights\n",
    "        outputs = tf.matmul(z, tf.transpose(w, perm=(0,2,1)))  # (num_att, batch, n_outputs) dot (num_att, n_outputs, n_features) = (num_att, batch, n_features)\n",
    "        # outputs = tf.reduce_mean(a, axis=[1])  # shape = (batch, n_features)\n",
    "        return outputs # (num_att, batch, n_features)\n",
    "\n",
    "    def get_config(self):\n",
    "        # Return the configuration parameters as a dictionary\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "            \"units\": self.units,\n",
    "            \"attn_norm_fn\": self.attn_norm_fn,\n",
    "            \"num_att\": self.num_att,\n",
    "            \"r\": self.r,\n",
    "            \"initializer\": self.initializer\n",
    "            })\n",
    "        return config\n",
    "     \n",
    "    #@classmethod\n",
    "    #def from_config(cls, config):\n",
    "    #    return cls(**config)\n",
    "\n",
    "@register_keras_serializable(name=\"_IterativeFeatureExclusion\")\n",
    "class _IterativeFeatureExclusion(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_features, n_outputs, attn_norm_fn, num_att=8, r=2, name=None, **kwargs):\n",
    "        super(_IterativeFeatureExclusion, self).__init__()\n",
    "\n",
    "        self.n_features = n_features\n",
    "        self.n_outputs = n_outputs\n",
    "        self.attn_norm_fn = attn_norm_fn\n",
    "        self.num_att = num_att\n",
    "        self.r = r\n",
    "        \n",
    "        self.attentions = [_Attention(self.n_outputs, self.attn_norm_fn, self.num_att, self.r) for i in range(self.n_features)]\n",
    "        mask_ones = np.ones((n_features,), dtype=np.int8)\n",
    "        self.masks = []\n",
    "        for j in range(0,n_features):\n",
    "            mask = mask_ones.copy()\n",
    "            mask[j] = 0\n",
    "            self.masks.append(tf.constant(mask, dtype=tf.float32))\n",
    "        #self.masks = tf.stack(self.masks, axis=1)\n",
    "\n",
    "    def call(self, inputs):       # input shape = (batch, n_features)\n",
    "        input_scores = []\n",
    "        for mask, attention in zip(self.masks,self.attentions):\n",
    "            inputs_masked = inputs * mask # shape = (num_att, batch, n_features)\n",
    "            z = tf.expand_dims(attention(inputs_masked), axis=-1) # (num_att, batch, n_features, 1)\n",
    "            input_scores.append(z)\n",
    "            \n",
    "        input_scores = tf.concat(input_scores, axis=-1) # shape = (num_att, batch, n_features, n_features)\n",
    "        input_scores = tf.reduce_mean(input_scores, axis=[-1]) # shape = (num_att, batch, n_features)\n",
    "        input_scores = tf.nn.softmax(input_scores, axis=-1) # shape = (num_att, batch, n_features)\n",
    "        return input_scores\n",
    "\n",
    "    def get_config(self):\n",
    "        # Serialize the list of attention layers using serialize_keras_object\n",
    "        attention_configs = [serialize_keras_object(attn) for attn in self.attentions]\n",
    "\n",
    "        # Convert masks into a list of arrays\n",
    "        #masks = [mask.numpy() for mask in self.masks]\n",
    "\n",
    "        # Return a configuration dictionary including parameters and serialized layers\n",
    "        base_config = super(_IterativeFeatureExclusion, self).get_config()\n",
    "        config = {\n",
    "            **base_config,\n",
    "            \"n_features\": self.n_features,\n",
    "            \"n_outputs\": self.n_outputs,\n",
    "            \"attn_norm_fn\": self.attn_norm_fn,\n",
    "            \"num_att\": self.num_att,\n",
    "            \"r\": self.r,\n",
    "            \"attentions\": attention_configs,  # serialized attention layers\n",
    "            #\"masks\": masks  # serialized masks\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Reconstruct the attention layers from the serialized configurations\n",
    "        attentions = [deserialize_keras_object(attn_config) for attn_config in config[\"attentions\"]]\n",
    "\n",
    "        # Reconstruct masks\n",
    "        #masks = [tf.constant(mask, dtype=tf.float32) for mask in config[\"masks\"]]\n",
    "\n",
    "        # Reconstruct the layer\n",
    "        layer = cls(\n",
    "            n_features=config[\"n_features\"],\n",
    "            n_outputs=config[\"n_outputs\"],\n",
    "            attn_norm_fn=config[\"attn_norm_fn\"],\n",
    "            num_att=config[\"num_att\"],\n",
    "            r=config[\"r\"]\n",
    "        )\n",
    "        # Assign the reconstructed attentions and masks to the layer\n",
    "        layer.attentions = attentions\n",
    "        #layer.masks = masks\n",
    "        return layer\n",
    "\n",
    "@register_keras_serializable(name=\"_IFEModule\")\n",
    "class _IFEModule(tf.keras.Model):\n",
    "    def __init__(self, data_config, model_config):\n",
    "        super(_IFEModule, self).__init__()\n",
    "        self._attn_norm_fn = 'softmax'\n",
    "\n",
    "        self._data_config = data_config\n",
    "        self._model_config = model_config\n",
    "\n",
    "        self._categorical_column_names = self._data_config.categorical_column_names\n",
    "        self._numerical_column_names = self._data_config.numerical_column_names\n",
    "        self._category_output_mode = self._data_config.category_output_mode\n",
    "        self._is_normalization = self._data_config.is_normalization\n",
    "        \n",
    "        self._num_att = self._model_config.num_att\n",
    "        self._r = self._model_config.r\n",
    "        # self._ife_num_layers = model_config.ife_num_layers\n",
    "\n",
    "        self._n_features = 0\n",
    "        self._encoder_layers = {}\n",
    "\n",
    "        self.data_batch = None\n",
    "        self.feature_indices = {}\n",
    "        self.input_scores = None\n",
    "\n",
    "    def _get_category_encoding_layer(self, name, dataset, dtype, max_tokens=None):\n",
    "        feature_ds = dataset.map(lambda x, y: x[name])\n",
    "        if dtype == tf.string:\n",
    "            index = tf.keras.layers.StringLookup(max_tokens=max_tokens)\n",
    "        elif dtype == tf.int64:\n",
    "            index = tf.keras.layers.IntegerLookup(max_tokens=max_tokens)\n",
    "        \n",
    "        index.adapt(feature_ds)\n",
    "        encoder = tf.keras.layers.CategoryEncoding(num_tokens=index.vocabulary_size(), output_mode=self._category_output_mode, name=name)\n",
    "        return lambda feature: encoder(index(feature))\n",
    "    \n",
    "    def _get_numerical_encoding_layer(self, name, dataset):\n",
    "        feature_ds = dataset.map(lambda x, y: x[name])\n",
    "        \n",
    "        if self._is_normalization:\n",
    "            encoder = tf.keras.layers.Normalization(axis=None)\n",
    "            encoder.adapt(feature_ds)\n",
    "            return lambda feature: encoder(feature)\n",
    "            return encoder\n",
    "        else:\n",
    "            return lambda feature: tf.cast(feature, dtype=tf.float32)\n",
    "        \n",
    "    def _create_encoder_layers(self, dataset, feature_names, feature_dtypes):\n",
    "        for name in feature_names:\n",
    "            if name in self._categorical_column_names:\n",
    "                layer = Lambda(self._get_category_encoding_layer(name, dataset, feature_dtypes[name]))\n",
    "                self._encoder_layers[name] = layer\n",
    "            elif name in self._numerical_column_names:\n",
    "                layer = Lambda(self._get_numerical_encoding_layer(name, dataset))\n",
    "                self._encoder_layers[name] = layer\n",
    "\n",
    "        st = 0\n",
    "        ed = 0\n",
    "        n_features = 0\n",
    "        for name, layer in self._encoder_layers.items():\n",
    "            example_input = next(iter(dataset.map(lambda x, y: x[name]))).numpy()\n",
    "            example_output = layer(example_input)\n",
    "            feature_size = example_output.shape[-1]  # Store the size (last dimension)\n",
    "            ed = st + feature_size\n",
    "            n_features = ed \n",
    "            index = list([st, ed])\n",
    "            st = ed\n",
    "            self.feature_indices[name] = index\n",
    "\n",
    "        return n_features\n",
    "\n",
    "    def get_feature_importance(self):\n",
    "        if not tf.is_symbolic_tensor(self.input_scores):\n",
    "            #self(self.data_batch)\n",
    "            reduction = (0, 1)\n",
    "            feature_scores = np.mean(self.input_scores, axis=reduction)\n",
    "            score = 0\n",
    "            feat_rank = {}\n",
    "            for feature, indices in self.feature_indices.items():\n",
    "                for j,i in enumerate(range(indices[0], indices[1])):\n",
    "                    name = feature + '[' + str(j) + ']'\n",
    "                    feat_rank[name] = feature_scores[i]\n",
    "            \n",
    "            df = pd.DataFrame(list(feat_rank.items()), columns=['Feature', 'Score'])\n",
    "            return df.sort_values(by='Score', ascending=False)\n",
    "        else:\n",
    "            msg = \"Please perform a prediction first to compute the feature importance scores.\"\n",
    "            print(\"\\033[91m {}\\033[00m\" .format(msg))\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(_IFEModule, self).get_config()\n",
    "        \n",
    "        # Serialize the data_config and model_config\n",
    "        data_config_dict = self._data_config.get_config()\n",
    "        model_config_dict = self._model_config.get_config()\n",
    "\n",
    "        # Serialize the encoder layers (which are created dynamically)\n",
    "        #encoder_layers_config = {name: serialize_keras_object(layer) for name, layer in self._encoder_layers.items()}\n",
    "\n",
    "        # Return the complete configuration\n",
    "        config = {\n",
    "            **base_config,\n",
    "            \"data_config\": data_config_dict,\n",
    "            \"model_config\": model_config_dict,\n",
    "            #\"encoder_layers\": encoder_layers_config,\n",
    "        }\n",
    "        \n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Deserialize the DataConfig and ModelConfig\n",
    "        data_config = DataConfig.from_config(config['data_config'])\n",
    "        model_config = ModelConfig.from_config(config['model_config'])\n",
    "\n",
    "        # Create an instance of _IFEModule\n",
    "        instance = cls(data_config, model_config)\n",
    "        \n",
    "        # Deserialize the encoder layers and assign them to the model\n",
    "        #encoder_layers = {name: deserialize_keras_object(layer_config) for name, layer_config in config['encoder_layers'].items()}\n",
    "        #instance._encoder_layers = encoder_layers\n",
    "        \n",
    "        # Return the reconstructed model\n",
    "        return instance\n",
    "    \n",
    "@register_keras_serializable(name=\"IFENetRegressor\")\n",
    "class IFENetRegressor(_IFEModule):\n",
    "    def __init__(self, data_config, model_config):\n",
    "        super(IFENetRegressor, self).__init__(data_config, model_config)\n",
    "\n",
    "        self.target_activation='linear'\n",
    "        # self._data_config = data_config\n",
    "        self._model_config = model_config\n",
    "\n",
    "        self._clf_num_layers = self._model_config.clf_num_layers\n",
    "        self._clf_hidden_units = self._model_config.clf_hidden_units\n",
    "        self._reduction = self._model_config.reduction_layer\n",
    "\n",
    "    def build_model(self, dataset):\n",
    "        if not isinstance(dataset, tf.data.Dataset):\n",
    "            raise ValueError(f\"Input must be a tf.data.Dataset, got {type(dataset)}.\")\n",
    "\n",
    "        feature_dtypes = {key: spec.dtype for key, spec in dataset.element_spec[0].items()}\n",
    "        feature_names = list(feature_dtypes.keys())\n",
    "        \n",
    "        self._n_features = self._create_encoder_layers(dataset, feature_names, feature_dtypes)\n",
    "\n",
    "        self._preprocess = tf.keras.layers.BatchNormalization(name='preprocess_batch_norm')\n",
    "\n",
    "        # Determine the number of responses\n",
    "        targets = next(iter(dataset.map(lambda x,y: y))).numpy()\n",
    "        n_outputs = targets.shape[1]\n",
    "        \n",
    "        self._ife_attn = _IterativeFeatureExclusion(self._n_features, n_outputs, self._attn_norm_fn, self._num_att, self._r)\n",
    "\n",
    "        # Build the predictive layers\n",
    "        clf_hidden_layers = []\n",
    "        for l in range(0, self._clf_num_layers):\n",
    "            clf_hidden_layers.append(tf.keras.layers.Dense(units=self._clf_hidden_units[l], activation='relu'))\n",
    "            clf_hidden_layers.append(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "        if self._reduction == 'flatten':\n",
    "            self._reduction_layer = tf.keras.layers.Flatten()\n",
    "        elif self._reduction == 'average':\n",
    "            self._reduction_layer = tf.keras.layers.GlobalAveragePooling1D()\n",
    "        \n",
    "        self.clf_hidden_layers = tf.keras.Sequential(clf_hidden_layers, name='fc_hidden_layers')\n",
    "        self.fc_out = tf.keras.layers.Dense(units=n_outputs, activation=self.target_activation, name='fc_out')\n",
    "        \n",
    "    def call(self, inputs): # (batch, n_features)\n",
    "        # preprocessing the inputs\n",
    "        features = [self._encoder_layers[name](inputs[name]) for name in self._encoder_layers]\n",
    "        \n",
    "        features = tf.concat(features, axis=1)\n",
    "\n",
    "        # features are the preprocessed inputs\n",
    "        batch_size = tf.shape(features)[0]\n",
    "        x = self._preprocess(features) # (batch, n_features)\n",
    "        norm_inputs = x\n",
    "        norm_inputs = tf.broadcast_to(norm_inputs, [self._num_att, batch_size, self._n_features]) # expand and broadcast it to the shape of input_scores\n",
    "        \n",
    "        self.input_scores = self._ife_attn(x)\n",
    "        x = norm_inputs * self.input_scores # (head, batch, n_features)\n",
    "\n",
    "        x = tf.transpose(x, perm=(1,0,2)) # (batch, head, n_features)\n",
    "        x = self._reduction_layer(x)\n",
    "\n",
    "        x = self.clf_hidden_layers(x)\n",
    "        outputs = self.fc_out(x)\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        # Serialize configuration of parent class (_IFEModule)\n",
    "        base_config = super(IFENetRegressor, self).get_config()\n",
    "\n",
    "        # Serialize the layer configurations for the layers created in build_model\n",
    "        preprocess_config = self._preprocess.get_config()  \n",
    "        ife_attn_config = self._ife_attn.get_config()  \n",
    "        reduction_config = self._reduction_layer.get_config()\n",
    "        # clf_hidden_layers_config = [layer.get_config() for layer in self.clf_hidden_layers.layers]\n",
    "        clf_hidden_layers_config = self.clf_hidden_layers.get_config()\n",
    "        fc_out_config = self.fc_out.get_config()\n",
    "\n",
    "        # Serialize the encoder layers (which are created dynamically)\n",
    "        encoder_layers_config = {name: serialize_keras_object(layer) for name, layer in self._encoder_layers.items()}\n",
    "\n",
    "        #self.feature_indices = {}\n",
    "        #self.input_scores = None\n",
    "        \n",
    "        config = {\n",
    "            **base_config,\n",
    "            \"n_features\": self._n_features,\n",
    "            \"target_activation\": self.target_activation,\n",
    "            \"clf_num_layers\": self._clf_num_layers,\n",
    "            \"clf_hidden_units\": self._clf_hidden_units,\n",
    "            \"reduction\": self._reduction,\n",
    "            \"feature_indices\": self.feature_indices,\n",
    "            \"reduction_layer\": reduction_config,\n",
    "            \"preprocess_config\": preprocess_config,\n",
    "            \"ife_attn_config\": ife_attn_config,\n",
    "            \"clf_hidden_layers_config\": clf_hidden_layers_config,\n",
    "            \"fc_out_config\": fc_out_config,\n",
    "            \"encoder_layers\": encoder_layers_config,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Restore the base configuration from the parent class (_IFEModule)\n",
    "        data_config = DataConfig.from_config(config['data_config'])\n",
    "        model_config = ModelConfig.from_config(config['model_config'])\n",
    "        \n",
    "        # Create an instance of IFENetRegressor with the restored configurations\n",
    "        instance = cls(data_config, model_config)\n",
    "\n",
    "        # Set the custom configurations for IFENetRegressor\n",
    "        instance.target_activation = config[\"target_activation\"]\n",
    "        instance._clf_num_layers = config[\"clf_num_layers\"]\n",
    "        instance._clf_hidden_units = config[\"clf_hidden_units\"]\n",
    "        instance._reduction = config[\"reduction\"]\n",
    "        instance._n_features = config[\"n_features\"]\n",
    "        instance.feature_indices = config[\"feature_indices\"]\n",
    "    \n",
    "        # Deserialize and set layers\n",
    "        instance._preprocess = tf.keras.layers.BatchNormalization.from_config(config[\"preprocess_config\"])\n",
    "        instance._ife_attn = _IterativeFeatureExclusion.from_config(config[\"ife_attn_config\"])\n",
    "        instance.clf_hidden_layers = tf.keras.Sequential.from_config(config[\"clf_hidden_layers_config\"])\n",
    "        instance.fc_out = tf.keras.layers.Dense.from_config(config[\"fc_out_config\"])\n",
    "\n",
    "        instance._reduction_layer = tf.keras.layers.Flatten() if instance._reduction == \"flatten\" else tf.keras.layers.GlobalAveragePooling1D()\n",
    "\n",
    "        # Deserialize the encoder layers and assign them to the model\n",
    "        encoder_layers = {name: deserialize_keras_object(layer_config) for name, layer_config in config[\"encoder_layers\"].items()}\n",
    "        instance._encoder_layers = encoder_layers\n",
    "    \n",
    "        # Rebuild the model layers (you need to pass a dataset to reconstruct model layers)\n",
    "        # Example: Replace 'dummy_dataset' with actual dataset\n",
    "        # instance.build_model(dummy_dataset)  # dummy_dataset should be passed to rebuild layers\n",
    "    \n",
    "        return instance\n",
    "\n",
    "@register_keras_serializable(name=\"IFENetClassifier\")\n",
    "class IFENetClassifier(_IFEModule):\n",
    "    def __init__(self, data_config, model_config):\n",
    "        super(IFENetClassifier, self).__init__(data_config, model_config)\n",
    "\n",
    "        self.target_activation = 'softmax'\n",
    "        self.data_config = data_config\n",
    "        self.model_config = model_config\n",
    "\n",
    "        self._clf_num_layers = self.model_config.clf_num_layers\n",
    "        self._clf_hidden_units = self.model_config.clf_hidden_units\n",
    "        self._reduction = self.model_config.reduction_layer\n",
    "\n",
    "        self._n_features = 0\n",
    "\n",
    "    def build_model(self, dataset):\n",
    "        if not isinstance(dataset, tf.data.Dataset):\n",
    "            raise ValueError(f\"Input must be a tf.data.Dataset, got {type(dataset)}.\")\n",
    "\n",
    "        self.data_batch = next(iter(dataset.map(lambda x, y: x)))\n",
    "        feature_dtypes = {key: spec.dtype for key, spec in dataset.element_spec[0].items()}\n",
    "        feature_names = list(feature_dtypes.keys())\n",
    "        \n",
    "        self._n_features = self._create_encoder_layers(dataset, feature_names, feature_dtypes)\n",
    "\n",
    "        self._preprocess = tf.keras.layers.BatchNormalization(name='preprocess_batch_norm')\n",
    "\n",
    "        # Determine the number of classes\n",
    "        labels = next(iter(dataset.map(lambda x,y: y))).numpy()\n",
    "        n_outputs = np.size(np.unique(labels))\n",
    "        \n",
    "        self._ife_attn = _IterativeFeatureExclusion(self._n_features, n_outputs, self._attn_norm_fn, self._num_att, self._r)\n",
    "\n",
    "        # Build the predictive layers\n",
    "        clf_hidden_layers = []\n",
    "        for l in range(0, self._clf_num_layers):\n",
    "            clf_hidden_layers.append(tf.keras.layers.Dense(units=self._clf_hidden_units[l], activation='relu'))\n",
    "            clf_hidden_layers.append(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "        if self._reduction == 'flatten':\n",
    "            self._reduction_layer = tf.keras.layers.Flatten()\n",
    "        elif self._reduction == 'average':\n",
    "            self._reduction_layer = tf.keras.layers.GlobalAveragePooling1D()\n",
    "        \n",
    "        self.clf_hidden_layers = tf.keras.Sequential(clf_hidden_layers, name='fc_hidden_layers')\n",
    "        self.fc_out = tf.keras.layers.Dense(units=n_outputs, activation=self.target_activation, name='fc_out')\n",
    "    \n",
    "    def call(self, inputs): # (batch, n_features)\n",
    "        # preprocessing the inputs\n",
    "        features = [self._encoder_layers[name](inputs[name]) for name in self._encoder_layers]\n",
    "        features = tf.concat(features, axis=1)\n",
    "        \n",
    "        # features are the preprocessed inputs\n",
    "        batch_size = tf.shape(features)[0]\n",
    "        x = self._preprocess(features) # (batch, n_features)\n",
    "        norm_inputs = x\n",
    "        norm_inputs = tf.broadcast_to(norm_inputs, [self._num_att, batch_size, self._n_features]) # expand and broadcast it to the shape of input_scores\n",
    "        \n",
    "        self.input_scores = self._ife_attn(x)\n",
    "        x = norm_inputs * self.input_scores\n",
    "        \n",
    "        x = tf.transpose(x, perm=(1,0,2))\n",
    "        x = self._reduction_layer(x)\n",
    "        \n",
    "        x = self.clf_hidden_layers(x)\n",
    "        outputs = self.fc_out(x)\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        # Serialize configuration of parent class (_IFEModule)\n",
    "        base_config = super(IFENetClassifier, self).get_config()\n",
    "\n",
    "        # Serialize the layer configurations for the layers created in build_model\n",
    "        preprocess_config = self._preprocess.get_config()  \n",
    "        ife_attn_config = self._ife_attn.get_config()  \n",
    "        reduction_config = self._reduction_layer.get_config()\n",
    "        # clf_hidden_layers_config = [layer.get_config() for layer in self.clf_hidden_layers.layers]\n",
    "        clf_hidden_layers_config = self.clf_hidden_layers.get_config()\n",
    "        fc_out_config = self.fc_out.get_config()\n",
    "\n",
    "        # Serialize the encoder layers (which are created dynamically)\n",
    "        encoder_layers_config = {name: serialize_keras_object(layer) for name, layer in self._encoder_layers.items()}\n",
    "\n",
    "        #self.feature_indices = {}\n",
    "        #self.input_scores = None\n",
    "        \n",
    "        config = {\n",
    "            **base_config,\n",
    "            \"n_features\": self._n_features,\n",
    "            \"target_activation\": self.target_activation,\n",
    "            \"clf_num_layers\": self._clf_num_layers,\n",
    "            \"clf_hidden_units\": self._clf_hidden_units,\n",
    "            \"reduction\": self._reduction,\n",
    "            \"feature_indices\": self.feature_indices,   \n",
    "            \"reduction_layer\": reduction_config,\n",
    "            \"preprocess_config\": preprocess_config,\n",
    "            \"ife_attn_config\": ife_attn_config,\n",
    "            \"clf_hidden_layers_config\": clf_hidden_layers_config,\n",
    "            \"fc_out_config\": fc_out_config,\n",
    "            \"encoder_layers\": encoder_layers_config,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Restore the base configuration from the parent class (_IFEModule)\n",
    "        data_config = DataConfig.from_config(config['data_config'])\n",
    "        model_config = ModelConfig.from_config(config['model_config'])\n",
    "        \n",
    "        # Create an instance of IFENetRegressor with the restored configurations\n",
    "        instance = cls(data_config, model_config)\n",
    "\n",
    "        # Set the custom configurations for IFENetRegressor\n",
    "        instance.target_activation = config[\"target_activation\"]\n",
    "        instance._clf_num_layers = config[\"clf_num_layers\"]\n",
    "        instance._clf_hidden_units = config[\"clf_hidden_units\"]\n",
    "        instance._reduction = config[\"reduction\"]\n",
    "        instance._n_features = config[\"n_features\"]        \n",
    "        instance.feature_indices = config[\"feature_indices\"]\n",
    "    \n",
    "        # Deserialize and set layers\n",
    "        instance._preprocess = tf.keras.layers.BatchNormalization.from_config(config[\"preprocess_config\"])\n",
    "        instance._ife_attn = _IterativeFeatureExclusion.from_config(config[\"ife_attn_config\"])\n",
    "        instance.clf_hidden_layers = tf.keras.Sequential.from_config(config[\"clf_hidden_layers_config\"])\n",
    "        instance.fc_out = tf.keras.layers.Dense.from_config(config[\"fc_out_config\"])\n",
    "\n",
    "        instance._reduction_layer = tf.keras.layers.Flatten() if instance._reduction == \"flatten\" else tf.keras.layers.GlobalAveragePooling1D()\n",
    "\n",
    "        # Deserialize the encoder layers and assign them to the model\n",
    "        encoder_layers = {name: deserialize_keras_object(layer_config) for name, layer_config in config[\"encoder_layers\"].items()}\n",
    "        instance._encoder_layers = encoder_layers\n",
    "    \n",
    "        return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0db88b55-7d7d-4ff6-93ef-14ec44df5f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10459, 24)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'heloc.data.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "columns = df.columns\n",
    "target_columns = ['RiskPerformance']\n",
    "\n",
    "num_col_names = ['ExternalRiskEstimate', 'MSinceOldestTradeOpen', 'MSinceMostRecentTradeOpen', \n",
    "                    'AverageMInFile', 'NumSatisfactoryTrades', 'NumTrades60Ever2DerogPubRec', \n",
    "                    'NumTrades90Ever2DerogPubRec', 'PercentTradesNeverDelq', 'MSinceMostRecentDelq',\n",
    "                    'MaxDelq2PublicRecLast12M', 'MaxDelqEver', 'NumTotalTrades',\n",
    "                    'NumTradesOpeninLast12M', 'PercentInstallTrades', 'MSinceMostRecentInqexcl7days', \n",
    "                    'NumInqLast6M', 'NumInqLast6Mexcl7days', 'NetFractionRevolvingBurden', \n",
    "                    'NetFractionInstallBurden', 'NumRevolvingTradesWBalance', 'NumInstallTradesWBalance',\n",
    "                    'NumBank2NatlTradesWHighUtilization', 'PercentTradesWBalance']\n",
    "cat_col_names = []\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a6ad0a90-4201-4234-87de-77b75db97829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (7000, 24)\n",
      "Validation set: (1359, 24)\n",
      "Test set: (2100, 24)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This split is according to Tab Survey (Borisov et al., 2022)\n",
    "train_size = 8359\n",
    "tmp, test = train_test_split(df, train_size=train_size, random_state=0)\n",
    "train, vald = train_test_split(tmp, train_size=7000, random_state=0)\n",
    "\n",
    "print(f'Training set: {train.shape}')\n",
    "print(f'Validation set: {vald.shape}')\n",
    "print(f'Test set: {test.shape}')\n",
    "\n",
    "batch_size = 256\n",
    "train_ds = dataframe_to_dataset(train, target_columns, batch_size=batch_size)\n",
    "vald_ds = dataframe_to_dataset(vald, target_columns, shuffle=False, batch_size=batch_size)\n",
    "test_ds = dataframe_to_dataset(test, target_columns, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "636946e9-9533-42df-8af0-947b071c2f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = DataConfig(categorical_column_names=cat_col_names, \n",
    "                         numerical_column_names=num_col_names,\n",
    "                         category_output_mode='one_hot',\n",
    "                         is_normalization=False)\n",
    "model_config = ModelConfig(num_att=16,\n",
    "                           r=3.5,\n",
    "                           clf_num_layers=1,\n",
    "                           clf_hidden_units=[32],\n",
    "                           reduction_layer='flatten')\n",
    "\n",
    "model = IFENetClassifier(data_config, model_config)\n",
    "model.build_model(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "565ff4db-873b-42a2-9c0d-811dab9ceda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "lr = 0.01\n",
    "lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=lr, \n",
    "                                                              decay_steps=2000,\n",
    "                                                              decay_rate=0.95,\n",
    "                                                              staircase=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n",
    "\n",
    "checkpoint_path = 'checkpoints/ifeNet_heloc.h5'\n",
    "patience = 500\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=patience, monitor='val_loss'),\n",
    "             tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, monitor='val_accuracy')]\n",
    "\n",
    "epochs = 5\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f5962958-ed12-440a-924f-cd9f26c7f7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/28 [==============================] - 6s 48ms/step - loss: 0.6347 - accuracy: 0.6937 - val_loss: 0.7781 - val_accuracy: 0.4842\n",
      "Epoch 2/5\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.5602 - accuracy: 0.7127 - val_loss: 0.7008 - val_accuracy: 0.5158\n",
      "Epoch 3/5\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.5537 - accuracy: 0.7191 - val_loss: 0.6885 - val_accuracy: 0.5320\n",
      "Epoch 4/5\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.5493 - accuracy: 0.7230 - val_loss: 0.6767 - val_accuracy: 0.5585\n",
      "Epoch 5/5\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.5510 - accuracy: 0.7244 - val_loss: 0.6442 - val_accuracy: 0.6144\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = 'saved_model/ifeNet_heloc.keras'\n",
    "model.fit(train_ds, validation_data=vald_ds, epochs=epochs, callbacks=callbacks)\n",
    "model.load_weights(checkpoint_path)\n",
    "model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "947b636f-1b93-4277-8687-f0c90f1e836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[(data,label)] = train_ds.take(1)\n",
    "#train_ds.element_spec[0]\n",
    "#model(data)\n",
    "#model.get_feature_importance(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a74b49b-323b-4b7a-93dc-3a5c3a87b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifenet = tf.keras.models.load_model(saved_model_path, safe_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd582be9-e439-4e15-b2cc-940a8c055dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.empty((0,))\n",
    "y_test = np.empty((0,))\n",
    "\n",
    "for data,label in test_ds.take(2):\n",
    "    y_hat = ifenet(data)\n",
    "    y_hat = np.argmax(y_hat, axis=-1)\n",
    "    y_pred = np.append(y_pred, y_hat.ravel())\n",
    "\n",
    "    label = label.numpy()\n",
    "    y_test = np.append(y_test, label.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52cb55c4-d799-41dc-8aa1-f64661b402e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66015625\n",
      "[[123 140]\n",
      " [ 34 215]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.47      0.59       263\n",
      "         1.0       0.61      0.86      0.71       249\n",
      "\n",
      "    accuracy                           0.66       512\n",
      "   macro avg       0.69      0.67      0.65       512\n",
      "weighted avg       0.70      0.66      0.65       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fb837ad3-dbd2-4a93-b565-a1e607a9585e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     0.076141\n",
       "0     0.063006\n",
       "3     0.050615\n",
       "2     0.050185\n",
       "14    0.049962\n",
       "21    0.045824\n",
       "13    0.044480\n",
       "9     0.044015\n",
       "6     0.043349\n",
       "22    0.042248\n",
       "10    0.041762\n",
       "17    0.040559\n",
       "8     0.039691\n",
       "15    0.039472\n",
       "19    0.039459\n",
       "4     0.039331\n",
       "5     0.038766\n",
       "20    0.038080\n",
       "12    0.036736\n",
       "16    0.035503\n",
       "1     0.035357\n",
       "11    0.033928\n",
       "18    0.031533\n",
       "Name: Score, dtype: float32"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ifenet(next(iter(test_ds.map(lambda x,y: x))))\n",
    "df = ifenet.get_feature_importance()\n",
    "df.Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "931db9f3-1bbf-446b-bdb0-9b7f8b006ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Feature     Score\n",
      "7               PercentTradesNeverDelq[0]  0.054695\n",
      "0                 ExternalRiskEstimate[0]  0.050520\n",
      "9             MaxDelq2PublicRecLast12M[0]  0.049224\n",
      "22               PercentTradesWBalance[0]  0.047680\n",
      "21  NumBank2NatlTradesWHighUtilization[0]  0.046080\n",
      "13                PercentInstallTrades[0]  0.045468\n",
      "15                        NumInqLast6M[0]  0.045055\n",
      "10                         MaxDelqEver[0]  0.044452\n",
      "6          NumTrades90Ever2DerogPubRec[0]  0.044073\n",
      "3                       AverageMInFile[0]  0.044012\n",
      "2            MSinceMostRecentTradeOpen[0]  0.044007\n",
      "20            NumInstallTradesWBalance[0]  0.043003\n",
      "16               NumInqLast6Mexcl7days[0]  0.042903\n",
      "19          NumRevolvingTradesWBalance[0]  0.042732\n",
      "17          NetFractionRevolvingBurden[0]  0.042486\n",
      "14        MSinceMostRecentInqexcl7days[0]  0.041946\n",
      "5          NumTrades60Ever2DerogPubRec[0]  0.041376\n",
      "12              NumTradesOpeninLast12M[0]  0.040857\n",
      "4                NumSatisfactoryTrades[0]  0.040300\n",
      "11                      NumTotalTrades[0]  0.039890\n",
      "8                 MSinceMostRecentDelq[0]  0.038474\n",
      "1                MSinceOldestTradeOpen[0]  0.035631\n",
      "18            NetFractionInstallBurden[0]  0.035137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor col,score in zip(columns, feat_scores):\\n    feat_rank[col] = score\\n\\ndf_feat_rank = pd.DataFrame(list(feat_rank.items()), columns=['Feature', 'Score'])\\ndf_feat_rank.sort_values(by='Score', ascending=False)\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_indices = model.feature_indices\n",
    "feature_scores = model.input_scores.numpy() # shape=(16, 256, 23)\n",
    "\n",
    "reduction = (0, 1)\n",
    "feature_scores = np.mean(feature_scores, axis=reduction)\n",
    "score = 0\n",
    "feat_rank = {}\n",
    "for feature, indices in feature_indices.items():\n",
    "    for j,i in enumerate(range(indices[0], indices[1])):\n",
    "        name = feature + '[' + str(j) + ']'\n",
    "        feat_rank[name] = feature_scores[i]\n",
    "\n",
    "df = pd.DataFrame(list(feat_rank.items()), columns=['Feature', 'Score'])\n",
    "print(df.sort_values(by='Score', ascending=False))\n",
    "'''\n",
    "for col,score in zip(columns, feat_scores):\n",
    "    feat_rank[col] = score\n",
    "\n",
    "df_feat_rank = pd.DataFrame(list(feat_rank.items()), columns=['Feature', 'Score'])\n",
    "df_feat_rank.sort_values(by='Score', ascending=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18ef5216-7a8e-47aa-94d7-6680c47dcf86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExternalRiskEstimate</td>\n",
       "      <td>0.050520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSinceOldestTradeOpen</td>\n",
       "      <td>0.035631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSinceMostRecentTradeOpen</td>\n",
       "      <td>0.044007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AverageMInFile</td>\n",
       "      <td>0.044012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NumSatisfactoryTrades</td>\n",
       "      <td>0.040300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NumTrades60Ever2DerogPubRec</td>\n",
       "      <td>0.041376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NumTrades90Ever2DerogPubRec</td>\n",
       "      <td>0.044073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PercentTradesNeverDelq</td>\n",
       "      <td>0.054695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSinceMostRecentDelq</td>\n",
       "      <td>0.038474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MaxDelq2PublicRecLast12M</td>\n",
       "      <td>0.049224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MaxDelqEver</td>\n",
       "      <td>0.044452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NumTotalTrades</td>\n",
       "      <td>0.039890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NumTradesOpeninLast12M</td>\n",
       "      <td>0.040857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PercentInstallTrades</td>\n",
       "      <td>0.045468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MSinceMostRecentInqexcl7days</td>\n",
       "      <td>0.041946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NumInqLast6M</td>\n",
       "      <td>0.045055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NumInqLast6Mexcl7days</td>\n",
       "      <td>0.042903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NetFractionRevolvingBurden</td>\n",
       "      <td>0.042486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NetFractionInstallBurden</td>\n",
       "      <td>0.035137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NumRevolvingTradesWBalance</td>\n",
       "      <td>0.042732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NumInstallTradesWBalance</td>\n",
       "      <td>0.043003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NumBank2NatlTradesWHighUtilization</td>\n",
       "      <td>0.046080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PercentTradesWBalance</td>\n",
       "      <td>0.047680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Feature     Score\n",
       "0                 ExternalRiskEstimate  0.050520\n",
       "1                MSinceOldestTradeOpen  0.035631\n",
       "2            MSinceMostRecentTradeOpen  0.044007\n",
       "3                       AverageMInFile  0.044012\n",
       "4                NumSatisfactoryTrades  0.040300\n",
       "5          NumTrades60Ever2DerogPubRec  0.041376\n",
       "6          NumTrades90Ever2DerogPubRec  0.044073\n",
       "7               PercentTradesNeverDelq  0.054695\n",
       "8                 MSinceMostRecentDelq  0.038474\n",
       "9             MaxDelq2PublicRecLast12M  0.049224\n",
       "10                         MaxDelqEver  0.044452\n",
       "11                      NumTotalTrades  0.039890\n",
       "12              NumTradesOpeninLast12M  0.040857\n",
       "13                PercentInstallTrades  0.045468\n",
       "14        MSinceMostRecentInqexcl7days  0.041946\n",
       "15                        NumInqLast6M  0.045055\n",
       "16               NumInqLast6Mexcl7days  0.042903\n",
       "17          NetFractionRevolvingBurden  0.042486\n",
       "18            NetFractionInstallBurden  0.035137\n",
       "19          NumRevolvingTradesWBalance  0.042732\n",
       "20            NumInstallTradesWBalance  0.043003\n",
       "21  NumBank2NatlTradesWHighUtilization  0.046080\n",
       "22               PercentTradesWBalance  0.047680"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e18c680-7dac-466f-a11d-595c2063fad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RiskPerformance</td>\n",
       "      <td>0.050520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExternalRiskEstimate</td>\n",
       "      <td>0.035631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSinceOldestTradeOpen</td>\n",
       "      <td>0.044007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSinceMostRecentTradeOpen</td>\n",
       "      <td>0.044012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AverageMInFile</td>\n",
       "      <td>0.040300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NumSatisfactoryTrades</td>\n",
       "      <td>0.041376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NumTrades60Ever2DerogPubRec</td>\n",
       "      <td>0.044073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumTrades90Ever2DerogPubRec</td>\n",
       "      <td>0.054695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PercentTradesNeverDelq</td>\n",
       "      <td>0.038474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MSinceMostRecentDelq</td>\n",
       "      <td>0.049224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MaxDelq2PublicRecLast12M</td>\n",
       "      <td>0.044452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MaxDelqEver</td>\n",
       "      <td>0.039890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NumTotalTrades</td>\n",
       "      <td>0.040857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NumTradesOpeninLast12M</td>\n",
       "      <td>0.045468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PercentInstallTrades</td>\n",
       "      <td>0.041946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MSinceMostRecentInqexcl7days</td>\n",
       "      <td>0.045055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NumInqLast6M</td>\n",
       "      <td>0.042903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NumInqLast6Mexcl7days</td>\n",
       "      <td>0.042486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NetFractionRevolvingBurden</td>\n",
       "      <td>0.035137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NetFractionInstallBurden</td>\n",
       "      <td>0.042732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NumRevolvingTradesWBalance</td>\n",
       "      <td>0.043003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NumInstallTradesWBalance</td>\n",
       "      <td>0.046080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NumBank2NatlTradesWHighUtilization</td>\n",
       "      <td>0.047680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Feature     Score\n",
       "0                      RiskPerformance  0.050520\n",
       "1                 ExternalRiskEstimate  0.035631\n",
       "2                MSinceOldestTradeOpen  0.044007\n",
       "3            MSinceMostRecentTradeOpen  0.044012\n",
       "4                       AverageMInFile  0.040300\n",
       "5                NumSatisfactoryTrades  0.041376\n",
       "6          NumTrades60Ever2DerogPubRec  0.044073\n",
       "7          NumTrades90Ever2DerogPubRec  0.054695\n",
       "8               PercentTradesNeverDelq  0.038474\n",
       "9                 MSinceMostRecentDelq  0.049224\n",
       "10            MaxDelq2PublicRecLast12M  0.044452\n",
       "11                         MaxDelqEver  0.039890\n",
       "12                      NumTotalTrades  0.040857\n",
       "13              NumTradesOpeninLast12M  0.045468\n",
       "14                PercentInstallTrades  0.041946\n",
       "15        MSinceMostRecentInqexcl7days  0.045055\n",
       "16                        NumInqLast6M  0.042903\n",
       "17               NumInqLast6Mexcl7days  0.042486\n",
       "18          NetFractionRevolvingBurden  0.035137\n",
       "19            NetFractionInstallBurden  0.042732\n",
       "20          NumRevolvingTradesWBalance  0.043003\n",
       "21            NumInstallTradesWBalance  0.046080\n",
       "22  NumBank2NatlTradesWHighUtilization  0.047680"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_feature_importance(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a36560ec-89e1-4eaf-83eb-c06708341e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elevation</td>\n",
       "      <td>0.127220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Soil_Type7</td>\n",
       "      <td>0.060129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Soil_Type37</td>\n",
       "      <td>0.057631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Soil_Type15</td>\n",
       "      <td>0.044712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Soil_Type8</td>\n",
       "      <td>0.039093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wilderness_Area1</td>\n",
       "      <td>0.035264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Horizontal_Distance_To_Roadways</td>\n",
       "      <td>0.029630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hillshade_Noon</td>\n",
       "      <td>0.029422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hillshade_9am</td>\n",
       "      <td>0.026024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Soil_Type36</td>\n",
       "      <td>0.024337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Slope</td>\n",
       "      <td>0.023465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Soil_Type18</td>\n",
       "      <td>0.021535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Soil_Type25</td>\n",
       "      <td>0.019394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Soil_Type35</td>\n",
       "      <td>0.018082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hillshade_3pm</td>\n",
       "      <td>0.018062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Horizontal_Distance_To_Hydrology</td>\n",
       "      <td>0.018017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wilderness_Area3</td>\n",
       "      <td>0.017555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Soil_Type1</td>\n",
       "      <td>0.017503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Soil_Type21</td>\n",
       "      <td>0.016906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Soil_Type34</td>\n",
       "      <td>0.016599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Soil_Type38</td>\n",
       "      <td>0.015525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Horizontal_Distance_To_Fire_Points</td>\n",
       "      <td>0.014728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Soil_Type27</td>\n",
       "      <td>0.014447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Soil_Type28</td>\n",
       "      <td>0.013442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vertical_Distance_To_Hydrology</td>\n",
       "      <td>0.013118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Soil_Type32</td>\n",
       "      <td>0.013044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Soil_Type22</td>\n",
       "      <td>0.012877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Soil_Type20</td>\n",
       "      <td>0.011980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Soil_Type31</td>\n",
       "      <td>0.011614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Soil_Type17</td>\n",
       "      <td>0.011607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Soil_Type9</td>\n",
       "      <td>0.011441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aspect</td>\n",
       "      <td>0.010871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wilderness_Area2</td>\n",
       "      <td>0.010731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Soil_Type6</td>\n",
       "      <td>0.010589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Soil_Type5</td>\n",
       "      <td>0.010118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Soil_Type3</td>\n",
       "      <td>0.009811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Soil_Type33</td>\n",
       "      <td>0.009791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Soil_Type13</td>\n",
       "      <td>0.009780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Soil_Type30</td>\n",
       "      <td>0.009470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Soil_Type29</td>\n",
       "      <td>0.009350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Soil_Type39</td>\n",
       "      <td>0.009291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Soil_Type23</td>\n",
       "      <td>0.008780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Soil_Type24</td>\n",
       "      <td>0.008220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Soil_Type2</td>\n",
       "      <td>0.008210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Soil_Type14</td>\n",
       "      <td>0.007813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Soil_Type19</td>\n",
       "      <td>0.007771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Soil_Type40</td>\n",
       "      <td>0.007762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Soil_Type4</td>\n",
       "      <td>0.007631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Soil_Type10</td>\n",
       "      <td>0.007594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wilderness_Area4</td>\n",
       "      <td>0.007238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Soil_Type11</td>\n",
       "      <td>0.006812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Soil_Type12</td>\n",
       "      <td>0.006083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Soil_Type26</td>\n",
       "      <td>0.006080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Soil_Type16</td>\n",
       "      <td>0.005778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Feature     Score\n",
       "0                            Elevation  0.127220\n",
       "20                          Soil_Type7  0.060129\n",
       "50                         Soil_Type37  0.057631\n",
       "28                         Soil_Type15  0.044712\n",
       "21                          Soil_Type8  0.039093\n",
       "10                    Wilderness_Area1  0.035264\n",
       "5      Horizontal_Distance_To_Roadways  0.029630\n",
       "7                       Hillshade_Noon  0.029422\n",
       "6                        Hillshade_9am  0.026024\n",
       "49                         Soil_Type36  0.024337\n",
       "2                                Slope  0.023465\n",
       "31                         Soil_Type18  0.021535\n",
       "38                         Soil_Type25  0.019394\n",
       "48                         Soil_Type35  0.018082\n",
       "8                        Hillshade_3pm  0.018062\n",
       "3     Horizontal_Distance_To_Hydrology  0.018017\n",
       "12                    Wilderness_Area3  0.017555\n",
       "14                          Soil_Type1  0.017503\n",
       "34                         Soil_Type21  0.016906\n",
       "47                         Soil_Type34  0.016599\n",
       "51                         Soil_Type38  0.015525\n",
       "9   Horizontal_Distance_To_Fire_Points  0.014728\n",
       "40                         Soil_Type27  0.014447\n",
       "41                         Soil_Type28  0.013442\n",
       "4       Vertical_Distance_To_Hydrology  0.013118\n",
       "45                         Soil_Type32  0.013044\n",
       "35                         Soil_Type22  0.012877\n",
       "33                         Soil_Type20  0.011980\n",
       "44                         Soil_Type31  0.011614\n",
       "30                         Soil_Type17  0.011607\n",
       "22                          Soil_Type9  0.011441\n",
       "1                               Aspect  0.010871\n",
       "11                    Wilderness_Area2  0.010731\n",
       "19                          Soil_Type6  0.010589\n",
       "18                          Soil_Type5  0.010118\n",
       "16                          Soil_Type3  0.009811\n",
       "46                         Soil_Type33  0.009791\n",
       "26                         Soil_Type13  0.009780\n",
       "43                         Soil_Type30  0.009470\n",
       "42                         Soil_Type29  0.009350\n",
       "52                         Soil_Type39  0.009291\n",
       "36                         Soil_Type23  0.008780\n",
       "37                         Soil_Type24  0.008220\n",
       "15                          Soil_Type2  0.008210\n",
       "27                         Soil_Type14  0.007813\n",
       "32                         Soil_Type19  0.007771\n",
       "53                         Soil_Type40  0.007762\n",
       "17                          Soil_Type4  0.007631\n",
       "23                         Soil_Type10  0.007594\n",
       "13                    Wilderness_Area4  0.007238\n",
       "24                         Soil_Type11  0.006812\n",
       "25                         Soil_Type12  0.006083\n",
       "39                         Soil_Type26  0.006080\n",
       "29                         Soil_Type16  0.005778"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch = None\n",
    "for i, batch in enumerate(test_ds):\n",
    "    if i == 0:  # Indexing starts at 0, so the second batch has index 1\n",
    "        first_batch = batch\n",
    "        break  # Once the second batch is found, break the loop\n",
    "\n",
    "data, label = first_batch\n",
    "model(data)\n",
    "\n",
    "feat_scores = model.input_scores\n",
    "feat_scores = np.mean(feat_scores, axis=(0,1))\n",
    "\n",
    "feat_rank = {}\n",
    "for col,score in zip(columns,feat_scores):\n",
    "    #print(f'{col}: {score}')\n",
    "    feat_rank[col] = score\n",
    "\n",
    "df_feat_rank = pd.DataFrame(list(feat_rank.items()), columns=['Feature', 'Score'])\n",
    "df_feat_rank.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "364a07d6-961c-41c3-8abc-145653345ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elevation</td>\n",
       "      <td>0.131297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Soil_Type7</td>\n",
       "      <td>0.060262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Soil_Type37</td>\n",
       "      <td>0.057748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Soil_Type15</td>\n",
       "      <td>0.044375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Soil_Type8</td>\n",
       "      <td>0.037752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wilderness_Area1</td>\n",
       "      <td>0.036080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Horizontal_Distance_To_Roadways</td>\n",
       "      <td>0.029566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hillshade_Noon</td>\n",
       "      <td>0.029403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Soil_Type36</td>\n",
       "      <td>0.024609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hillshade_9am</td>\n",
       "      <td>0.023704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Slope</td>\n",
       "      <td>0.022405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Soil_Type18</td>\n",
       "      <td>0.021359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hillshade_3pm</td>\n",
       "      <td>0.019857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Soil_Type25</td>\n",
       "      <td>0.019659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Soil_Type35</td>\n",
       "      <td>0.017578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Soil_Type1</td>\n",
       "      <td>0.017577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wilderness_Area3</td>\n",
       "      <td>0.017233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Horizontal_Distance_To_Hydrology</td>\n",
       "      <td>0.017106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Soil_Type21</td>\n",
       "      <td>0.016443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Soil_Type34</td>\n",
       "      <td>0.015728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Soil_Type38</td>\n",
       "      <td>0.015290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Horizontal_Distance_To_Fire_Points</td>\n",
       "      <td>0.015106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Soil_Type27</td>\n",
       "      <td>0.014788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Soil_Type28</td>\n",
       "      <td>0.013800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Soil_Type32</td>\n",
       "      <td>0.013036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vertical_Distance_To_Hydrology</td>\n",
       "      <td>0.012701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Soil_Type20</td>\n",
       "      <td>0.012394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Soil_Type22</td>\n",
       "      <td>0.012279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Soil_Type31</td>\n",
       "      <td>0.011925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Soil_Type9</td>\n",
       "      <td>0.011894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aspect</td>\n",
       "      <td>0.011474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Soil_Type17</td>\n",
       "      <td>0.011389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Soil_Type5</td>\n",
       "      <td>0.010481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Soil_Type6</td>\n",
       "      <td>0.010376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wilderness_Area2</td>\n",
       "      <td>0.010288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Soil_Type29</td>\n",
       "      <td>0.009861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Soil_Type13</td>\n",
       "      <td>0.009735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Soil_Type30</td>\n",
       "      <td>0.009285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Soil_Type33</td>\n",
       "      <td>0.009279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Soil_Type3</td>\n",
       "      <td>0.009095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Soil_Type39</td>\n",
       "      <td>0.009072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Soil_Type23</td>\n",
       "      <td>0.008844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Soil_Type24</td>\n",
       "      <td>0.008769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Soil_Type2</td>\n",
       "      <td>0.008395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Soil_Type4</td>\n",
       "      <td>0.007836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Soil_Type14</td>\n",
       "      <td>0.007833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Soil_Type19</td>\n",
       "      <td>0.007809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Soil_Type40</td>\n",
       "      <td>0.007682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Soil_Type10</td>\n",
       "      <td>0.007225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wilderness_Area4</td>\n",
       "      <td>0.007099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Soil_Type11</td>\n",
       "      <td>0.006998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Soil_Type12</td>\n",
       "      <td>0.006314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Soil_Type26</td>\n",
       "      <td>0.006019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Soil_Type16</td>\n",
       "      <td>0.005870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Feature     Score\n",
       "0                            Elevation  0.131297\n",
       "20                          Soil_Type7  0.060262\n",
       "50                         Soil_Type37  0.057748\n",
       "28                         Soil_Type15  0.044375\n",
       "21                          Soil_Type8  0.037752\n",
       "10                    Wilderness_Area1  0.036080\n",
       "5      Horizontal_Distance_To_Roadways  0.029566\n",
       "7                       Hillshade_Noon  0.029403\n",
       "49                         Soil_Type36  0.024609\n",
       "6                        Hillshade_9am  0.023704\n",
       "2                                Slope  0.022405\n",
       "31                         Soil_Type18  0.021359\n",
       "8                        Hillshade_3pm  0.019857\n",
       "38                         Soil_Type25  0.019659\n",
       "48                         Soil_Type35  0.017578\n",
       "14                          Soil_Type1  0.017577\n",
       "12                    Wilderness_Area3  0.017233\n",
       "3     Horizontal_Distance_To_Hydrology  0.017106\n",
       "34                         Soil_Type21  0.016443\n",
       "47                         Soil_Type34  0.015728\n",
       "51                         Soil_Type38  0.015290\n",
       "9   Horizontal_Distance_To_Fire_Points  0.015106\n",
       "40                         Soil_Type27  0.014788\n",
       "41                         Soil_Type28  0.013800\n",
       "45                         Soil_Type32  0.013036\n",
       "4       Vertical_Distance_To_Hydrology  0.012701\n",
       "33                         Soil_Type20  0.012394\n",
       "35                         Soil_Type22  0.012279\n",
       "44                         Soil_Type31  0.011925\n",
       "22                          Soil_Type9  0.011894\n",
       "1                               Aspect  0.011474\n",
       "30                         Soil_Type17  0.011389\n",
       "18                          Soil_Type5  0.010481\n",
       "19                          Soil_Type6  0.010376\n",
       "11                    Wilderness_Area2  0.010288\n",
       "42                         Soil_Type29  0.009861\n",
       "26                         Soil_Type13  0.009735\n",
       "43                         Soil_Type30  0.009285\n",
       "46                         Soil_Type33  0.009279\n",
       "16                          Soil_Type3  0.009095\n",
       "52                         Soil_Type39  0.009072\n",
       "36                         Soil_Type23  0.008844\n",
       "37                         Soil_Type24  0.008769\n",
       "15                          Soil_Type2  0.008395\n",
       "17                          Soil_Type4  0.007836\n",
       "27                         Soil_Type14  0.007833\n",
       "32                         Soil_Type19  0.007809\n",
       "53                         Soil_Type40  0.007682\n",
       "23                         Soil_Type10  0.007225\n",
       "13                    Wilderness_Area4  0.007099\n",
       "24                         Soil_Type11  0.006998\n",
       "25                         Soil_Type12  0.006314\n",
       "39                         Soil_Type26  0.006019\n",
       "29                         Soil_Type16  0.005870"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_batch = None\n",
    "for i, batch in enumerate(test_ds):\n",
    "    if i == 1:  # Indexing starts at 0, so the second batch has index 1\n",
    "        second_batch = batch\n",
    "        break  # Once the second batch is found, break the loop\n",
    "\n",
    "data,label = second_batch\n",
    "model(data)\n",
    "\n",
    "feat_scores = model.input_scores\n",
    "feat_scores = np.mean(feat_scores, axis=(0,1))\n",
    "\n",
    "feat_rank = {}\n",
    "for col,score in zip(columns,feat_scores):\n",
    "    #print(f'{col}: {score}')\n",
    "    feat_rank[col] = score\n",
    "\n",
    "df_feat_rank = pd.DataFrame(list(feat_rank.items()), columns=['Feature', 'Score'])\n",
    "df_feat_rank.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d866e6c-c0cb-478d-83c6-205ee36fc2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
