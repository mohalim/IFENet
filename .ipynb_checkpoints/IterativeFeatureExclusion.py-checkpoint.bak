"""
Created on Mon Nov 10 14:10:00 2024
@author: Fathe, Abdulrahman and Mohd Halim
"""

import tensorflow as tf
import numpy as np

from FeatureEncoder import FeatureEncoder

class Attention(tf.keras.layers.Layer):
    def __init__(self, units, r=2, initializer="glorot_uniform"):
        super(Attention, self).__init__()
        self.units = units # number of classes
        self.r = r
        self.initializer = initializer

    def build(self, input_shape): # input_shape = (batch, n_features)
        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),
                                      initializer=self.initializer,
                                      trainable=True,
                                      name='kernel') # shape = (n_features, n_classes)

    def call(self, inputs): # input_shape = (batch, n_features)
        z = tf.matmul(inputs, self.kernel) # shape = (batch, n_classes)
        # z = tf.nn.softmax(z, axis=-1)
        z = tf.nn.sigmoid(z)
        
        w = tf.math.exp(self.kernel * self.r) # amplify weights
        a = tf.matmul(z, tf.transpose(w))  # (batch x n_classes) dot (n_classes, n_features) = (batch, n_features)
        outputs = tf.reduce_mean(a, axis=0)  # shape = (n_features,)
        return outputs

class IterativeFeatureExclusion(tf.keras.layers.Layer):
    def __init__(self, n_features, n_classes, r=2):
        super(IterativeFeatureExclusion, self).__init__()
        self.attentions = [Attention(n_classes, r=r) for i in range(n_features)]
        self.mask = np.ones((n_features,), dtype=np.int8)

    def call(self, inputs):       # input shape = (batch, n_features)
        input_scores = []
        
        for e, j in enumerate(self.attentions):
            mask = self.mask.copy()
            mask[e] = 0
            inputs_masked = inputs * mask # shape = (batch, n_features)
            z = tf.expand_dims(self.attentions[e](inputs_masked), axis=-1)
            input_scores.append(z)
            
        input_scores = tf.concat(input_scores, axis=1) # shape = (n_features, n_features)
        input_scores = tf.reduce_mean(input_scores, axis=1) # shape = (n_features, )
        input_scores = tf.nn.softmax(input_scores, axis=0) # shape = (n_features, )
        # input_scores = tf.nn.sigmoid(input_scores) # shape = (n_features, )
        return input_scores

class IFENetClassifier(tf.keras.Model):
    def __init__(self, **kwargs):
        super(IFENetClassifier, self).__init__()
        
        n_features = kwargs['n_features']
        n_classes = kwargs['n_classes']
        ife_num_layers = kwargs['ife_num_layers']
        clf_hidden_size = kwargs['clf_hidden_size']
        r = kwargs['r']
        
        self.input_scores = None
        self.n_features = n_features
        self.preprocess = tf.keras.layers.BatchNormalization(input_shape=(self.n_features,), name='preprocess')
        self.ife_attns = [IterativeFeatureExclusion(n_features, n_classes, r) for l in range(0,ife_num_layers)]
        
        self.fc_hidden = tf.keras.layers.Dense(units=clf_hidden_size, name='fc_hidden')
        self.layernorm = tf.keras.layers.LayerNormalization(name='layer_norm')
        self.relu = tf.keras.layers.ReLU(name='relu')
        self.fc_out = tf.keras.layers.Dense(units=n_classes, name='fc_out')
        self.softmax = tf.keras.layers.Softmax()

    def call(self, inputs):
        x = self.preprocess(inputs)
        norm_inputs = x

        for ife_attn in self.ife_attns:
            score = ife_attn(x)
            x = x * score
        
        self.input_scores = score
        x = norm_inputs * score
        x = self.fc_hidden(x)
        x = self.layernorm(x)
        x = self.relu(x)
        x = self.fc_out(x)
        outputs = self.softmax(x)
        return outputs
        
    def build(self, input_shape):
        x = tf.keras.layers.Input(shape=(self.n_features,))
        return tf.keras.models.Model(inputs=x, outputs=self.call(x))


